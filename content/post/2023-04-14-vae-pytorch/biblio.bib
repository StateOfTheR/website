@inproceedings{KingmaWelling2014,
  author       = {Diederik P. Kingma and
                  Max Welling},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {Auto-Encoding Variational Bayes},
  booktitle    = {2nd International Conference on Learning Representations, {ICLR} 2014,
                  Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year         = {2014},
  url          = {http://arxiv.org/abs/1312.6114},
  timestamp    = {Thu, 04 Apr 2019 13:20:07 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/KingmaW13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{zhao20c,
  title = 	 {Variational Autoencoders for Sparse and Overdispersed Discrete Data},
  author =       {Zhao, He and Rai, Piyush and Du, Lan and Buntine, Wray and Phung, Dinh and Zhou, Mingyuan},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1684--1694},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/zhao20c/zhao20c.pdf},
  url = 	 {https://proceedings.mlr.press/v108/zhao20c.html},
  abstract = 	 {Many applications, such as text modelling, high-throughput sequencing, and recommender systems, require analysing sparse, high-dimensional, and overdispersed discrete (count or binary) data. Recent deep probabilistic models based on variational autoencoders (VAE) have shown promising results on discrete data but may have inferior modelling performance due to the insufficient capability in modelling overdispersion and model misspecification. To address these issues, we develop a VAE-based framework using the negative binomial distribution as the data distribution. We also provide an analysis of its properties vis-à-vis other models. We conduct extensive experiments on three problems from discrete data analysis: text analysis/topic modelling, collaborative filtering, and multi-label learning. Our models outperform state-of-the-art approaches on these problems, while also capturing the phenomenon of overdispersion more effectively.}
}

@inproceedings{JangGP17,
  author       = {Eric Jang and
                  Shixiang Gu and
                  Ben Poole},
  title        = {Categorical Reparameterization with Gumbel-Softmax},
  booktitle    = {5th International Conference on Learning Representations, {ICLR} 2017,
                  Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2017},
  url          = {https://openreview.net/forum?id=rkE3y85ee},
  timestamp    = {Thu, 25 Jul 2019 14:26:04 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/JangGP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Gronbech2020,
    author = {Grønbech, Christopher Heje and Vording, Maximillian Fornitz and Timshel, Pascal N and Sønderby, Casper Kaae and Pers, Tune H and Winther, Ole},
    title = "{scVAE: variational auto-encoders for single-cell gene expression data}",
    journal = {Bioinformatics},
    volume = {36},
    number = {16},
    pages = {4415-4422},
    year = {2020},
    month = {05},
    abstract = "{Models for analysing and making relevant biological inferences from massive amounts of complex single-cell transcriptomic data typically require several individual data-processing steps, each with their own set of hyperparameter choices. With deep generative models one can work directly with count data, make likelihood-based model comparison, learn a latent representation of the cells and capture more of the variability in different cell populations.We propose a novel method based on variational auto-encoders (VAEs) for analysis of single-cell RNA sequencing (scRNA-seq) data. It avoids data preprocessing by using raw count data as input and can robustly estimate the expected gene expression levels and a latent representation for each cell. We tested several count likelihood functions and a variant of the VAE that has a priori clustering in the latent space. We show for several scRNA-seq datasets that our method outperforms recently proposed scRNA-seq methods in clustering cells and that the resulting clusters reflect cell types.Our method, called scVAE, is implemented in Python using the TensorFlow machine-learning library, and it is freely available at https://github.com/scvae/scvae.Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btaa293},
    url = {https://doi.org/10.1093/bioinformatics/btaa293},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/36/16/4415/33965265/btaa293.pdf},
}

