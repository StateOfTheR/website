---
title: Practical session - Introduction to Bayesian deep learning in Python
author: State of the R
date: '2021-11-26'
slug: bayesian-deep-learning
categories: ["workshop"]
tags: ["bayesian", "deep learning", "Python"]
subtitle: ''
summary: ''
authors: []
lastmod: '2021-11-26T16:03:33+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

[Charles Ollion](https://github.com/charlesollion) et [Sylvain Le Corff](https://sylvainlc.github.io/) (CMAP) nous ont proposé une session pratique autour de l'apprentissage profond bayésien. 

 
Summary   
Deep learning is widely used for regression and classification problems, but the simplest architectures do not capture model uncertainty. Most widespread solutions provide single point estimates in regression problems instead of designing predictive or posterior distributions.
Several approaches have tried to tie Deep Learning with Bayesian models, such as Bayes by Backprop and practical techniques such as Monte Carlo Dropout. 
During this session, we propose a hands-on tutorial with such approaches, using Python (Tensorflow / Pytorch). 
We propose a workshop that you may follow using Google Colab (no installation or requirements).
After an in-depth description of the model and the datasets, we will take time to deeply understand the models and focus on the implementation details.  

Level: basic / intermediate
Prerequisite: small experience in Python 

Lien vers le [tutoriel](https://colab.research.google.com/github/charlesollion/dlexperiments/blob/master/6-Bayesian-DL/BayesianDeepWine.ipynb)
et le dépôt [github](https://github.com/charlesollion/dlexperiments/tree/master/6-Bayesian-DL)

Papers
Weight uncertainty in neural networks aka Bayes by Backprop https://arxiv.org/abs/1505.05424
Dropout as Bayesian approximation aka Monte Carlo dropout https://arxiv.org/pdf/1506.02142.pdf
Evaluating predictive distributions https://arxiv.org/pdf/2110.04629.pdf
